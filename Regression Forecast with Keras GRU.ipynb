{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import GRU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Open</th>\n",
       "      <th>High</th>\n",
       "      <th>Low</th>\n",
       "      <th>Close</th>\n",
       "      <th>Volume</th>\n",
       "      <th>VIXCLS</th>\n",
       "      <th>RETURN</th>\n",
       "      <th>sVIXCLS</th>\n",
       "      <th>sVolume</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2015-01-05</th>\n",
       "      <td>20.13</td>\n",
       "      <td>20.19</td>\n",
       "      <td>19.70</td>\n",
       "      <td>19.79</td>\n",
       "      <td>4948799.0</td>\n",
       "      <td>19.92</td>\n",
       "      <td>-0.016890</td>\n",
       "      <td>1.058288</td>\n",
       "      <td>-0.788890</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2015-01-06</th>\n",
       "      <td>19.82</td>\n",
       "      <td>19.84</td>\n",
       "      <td>19.17</td>\n",
       "      <td>19.19</td>\n",
       "      <td>4944121.0</td>\n",
       "      <td>21.12</td>\n",
       "      <td>-0.030318</td>\n",
       "      <td>1.344465</td>\n",
       "      <td>-0.789530</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2015-01-07</th>\n",
       "      <td>19.33</td>\n",
       "      <td>19.50</td>\n",
       "      <td>19.08</td>\n",
       "      <td>19.14</td>\n",
       "      <td>8045186.0</td>\n",
       "      <td>19.31</td>\n",
       "      <td>-0.002606</td>\n",
       "      <td>0.912814</td>\n",
       "      <td>-0.365413</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2015-01-08</th>\n",
       "      <td>19.36</td>\n",
       "      <td>19.98</td>\n",
       "      <td>19.35</td>\n",
       "      <td>19.86</td>\n",
       "      <td>7094534.0</td>\n",
       "      <td>17.01</td>\n",
       "      <td>0.037618</td>\n",
       "      <td>0.364307</td>\n",
       "      <td>-0.495429</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2015-01-09</th>\n",
       "      <td>19.93</td>\n",
       "      <td>20.09</td>\n",
       "      <td>19.66</td>\n",
       "      <td>19.94</td>\n",
       "      <td>5238601.0</td>\n",
       "      <td>17.55</td>\n",
       "      <td>0.004028</td>\n",
       "      <td>0.493087</td>\n",
       "      <td>-0.749256</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             Open   High    Low  Close     Volume  VIXCLS    RETURN   sVIXCLS  \\\n",
       "2015-01-05  20.13  20.19  19.70  19.79  4948799.0   19.92 -0.016890  1.058288   \n",
       "2015-01-06  19.82  19.84  19.17  19.19  4944121.0   21.12 -0.030318  1.344465   \n",
       "2015-01-07  19.33  19.50  19.08  19.14  8045186.0   19.31 -0.002606  0.912814   \n",
       "2015-01-08  19.36  19.98  19.35  19.86  7094534.0   17.01  0.037618  0.364307   \n",
       "2015-01-09  19.93  20.09  19.66  19.94  5238601.0   17.55  0.004028  0.493087   \n",
       "\n",
       "             sVolume  \n",
       "2015-01-05 -0.788890  \n",
       "2015-01-06 -0.789530  \n",
       "2015-01-07 -0.365413  \n",
       "2015-01-08 -0.495429  \n",
       "2015-01-09 -0.749256  "
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import pandas_datareader.data as web\n",
    "\n",
    "import datetime\n",
    "\n",
    "start = datetime.datetime(2015, 1, 1)\n",
    "\n",
    "TICKER = 'NVDA'\n",
    "DAILY_DATA = web.DataReader(TICKER, \"google\", start)\n",
    "VIX = web.DataReader(\"VIXCLS\", \"fred\", start)\n",
    "\n",
    "_DATA = pd.concat([DAILY_DATA, VIX], axis=1).dropna()\n",
    "_DATA['RETURN'] = _DATA.Close.pct_change()\n",
    "_DATA['sVIXCLS'] = StandardScaler().fit_transform(_DATA.VIXCLS.values.reshape(_DATA.VIXCLS.shape[0],1))\n",
    "_DATA['sVolume'] = StandardScaler().fit_transform(_DATA.Volume.values.reshape(_DATA.Volume.shape[0],1))\n",
    "_DATA = _DATA[1:]\n",
    "_DATA.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "lookback = 30\n",
    "horizon = 30\n",
    "test_samples = 7\n",
    "PREDICTORS = ['RETURN','sVIXCLS','sVolume']\n",
    "\n",
    "TRAIN = _DATA.iloc[:-(lookback + horizon + test_samples)]\n",
    "TEST = _DATA.iloc[-(lookback + horizon + test_samples):]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(7, 3, 30)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "TEST_X = []\n",
    "TEST_Y = []\n",
    "\n",
    "for i in range( TEST.shape[0] -(lookback + horizon ) ):\n",
    "    TEST_X.append( np.array(TEST.iloc[i:i + lookback][PREDICTORS].T ) )\n",
    "    TEST_Y.append( np.array(TEST.iloc[i + lookback:i + lookback + horizon ][PREDICTORS].T ) ) \n",
    "    \n",
    "TEST_X = np.array(TEST_X)\n",
    "#TEST_X = TEST_X.reshape(TEST_X.shape[0], 1, lookback)\n",
    "\n",
    "TEST_Y = np.array(TEST_Y)\n",
    "#TEST_Y = TEST_Y.reshape(TEST_Y.shape[0], 1, horizon)\n",
    "\n",
    "TEST_X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(481, 3, 30)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "TRAIN_X = []\n",
    "TRAIN_Y = []\n",
    "\n",
    "for i in range( TRAIN.shape[0] -(lookback + horizon) + 1 ):\n",
    "    TRAIN_X.append( np.array(TRAIN.iloc[i:i + lookback][PREDICTORS].T ) )\n",
    "    TRAIN_Y.append( np.array(TRAIN.iloc[i + lookback:i + lookback + horizon ][PREDICTORS].T ) )\n",
    "    \n",
    "TRAIN_X = np.array(TRAIN_X)\n",
    "#TRAIN_X = TRAIN_X.reshape(TRAIN_X.shape[0], 1, lookback)\n",
    "\n",
    "TRAIN_Y = np.array(TRAIN_Y)\n",
    "#TRAIN_Y = TRAIN_Y.reshape(TRAIN_Y.shape[0], 1, horizon )\n",
    "\n",
    "TRAIN_X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Build Model\n",
    "model = Sequential()  \n",
    "model.add(GRU(lookback, input_shape=(TRAIN_X.shape[1], TRAIN_X.shape[2]), return_sequences=True, activation='relu', name='GRU_1') )\n",
    "model.add(GRU(lookback + 10, return_sequences=True, activation='relu', name='GRU_2'))\n",
    "model.add(GRU(lookback + 10, return_sequences=True, activation='relu', name='GRU_3'))\n",
    "model.add(GRU(horizon, return_sequences=True, activation='linear', name='GRU_4'))\n",
    "#model.add(Dense(horizon, activation='linear'))\n",
    "\n",
    "model.compile(loss='mse', optimizer='adam', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import load_model\n",
    "\n",
    "model = load_model('{}_MODEL.h5'.format(TICKER))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fit the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "model.fit(TRAIN_X, TRAIN_Y, epochs=35000, validation_data=(TEST_X, TEST_Y), batch_size=TRAIN_X.shape[0], verbose=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model.save('{}_MODEL.h5'.format(TICKER), overwrite=True)  # creates a HDF5 file 'my_model.h5'\n",
    "#del model  # deletes the existing model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "FITTED = model.predict(TRAIN_X)\n",
    "TEST_PREDICTION = model.predict(TEST_X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bokeh.io import show, output_notebook\n",
    "from bokeh.plotting import figure\n",
    "from bokeh.layouts import column\n",
    "from bokeh.models import Jitter\n",
    "output_notebook()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "x_range = list(range(TRAIN_X.shape[0]))\n",
    "\n",
    "p1 = figure(title=\"Fitted vs. Actual Returns\" , plot_width=900 , plot_height=300)\n",
    "p1.line( x=x_range , y=TRAIN_Y[:,0,0].flatten().tolist() , alpha=0.5 , legend=\"Target\")\n",
    "p1.line( x=x_range , y=FITTED[:,0,0].flatten().tolist() , color='red' , alpha=0.5 , legend=\"Fitted\")\n",
    "\n",
    "p2 = figure(title=\"Fitted Same Direction as Actual\" , plot_width=900 , plot_height=300)\n",
    "p2.circle( x=x_range , alpha=0.5 , y=((FITTED>0.0) == (TRAIN_Y>0.0))[:,0,1].flatten().tolist() )\n",
    "\n",
    "p3 = figure(title=\"Fitted Returns - Actual Returns\" , plot_width=900 , plot_height=300)\n",
    "p3.circle( x=x_range , y=( FITTED - TRAIN_Y )[:,0,0].flatten().tolist() , color='orange' , alpha=0.5)\n",
    "\n",
    "p4 = figure(title=\"Test Predicted vs. Target\" , plot_width=900 , plot_height=300)\n",
    "p4.circle( x=TEST_PREDICTION[0,0,:] , y=TEST_Y[0,0,:] , color='red' , alpha=0.5)\n",
    "\n",
    "p1.x_range = p2.x_range = p3.x_range\n",
    "\n",
    "show(column(p1,p2,p3,p4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# accuracy by horizon time step\n",
    "for i in range( horizon ):\n",
    "    print( ((FITTED>0) == (TRAIN_Y>0))[:,0,i].astype(int).flatten().sum()/TRAIN_Y.shape[0] )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for i in range( horizon ):\n",
    "    print( ((TEST_PREDICTION>0) == (TEST_Y>0))[:,0,i].astype(int).flatten().sum()/TEST_Y.shape[0] )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "(TEST_Y - TEST_PREDICTION)/TEST_Y"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
